{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import tqdm\n",
    "from torchfuzzy import FuzzyLayer, DefuzzyLinearLayer, FuzzyBellLayer\n",
    "import piqa\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.manifold import TSNE\n",
    "from torchvision.transforms import v2\n",
    "from torchinfo import summary\n",
    "from matplotlib.colors import ListedColormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 300\n",
    "latent_dim = 3\n",
    "mnist_class_anomaly = 4\n",
    "kernels = 16\n",
    "fuzzy_rules_count = 10\n",
    "\n",
    "prefix = f\"fuzzy_ad\"\n",
    "writer = SummaryWriter(f'runs/mnist/{prefix}_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "binary_cmap = ListedColormap(['yellow', 'red'], N=2)\n",
    "ssim = piqa.SSIM(window_size = 11, n_channels=1, reduction='none').to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет\n",
    "\n",
    "1. Исключаем класс аномалии `mnist_class_anomaly` из общей выборк\n",
    "2. Убираем метки с остальных классов\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_and_transform(x):\n",
    "    nimg = x.view(-1, 28, 28)\n",
    "    nimg = torch.clamp(nimg, 0, 1)\n",
    "    return nimg\n",
    "\n",
    "def clamp(x):\n",
    "    #nimg = 2.0*(x.view(-1, 28, 28) - 0.5)\n",
    "    nimg = torch.clamp(x, 0, 1)\n",
    "    return nimg\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(norm_and_transform)\n",
    "])\n",
    "\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomRotation(15, fill=0), \n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), fill=0), \n",
    "    #transforms.RandomCrop(size=26),\n",
    "    #transforms.Resize(size=(28, 28)),\n",
    "    transforms.Lambda(clamp)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDatasetWithIdx(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self._dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (*self._dataset[idx], idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([54158, 10])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_target_and_mask(target_label):\n",
    "    t = target_label\n",
    "    return t \n",
    "\n",
    "train_data =MNISTDatasetWithIdx(datasets.MNIST(\n",
    "    '~/.pytorch/MNIST_data/', \n",
    "    download=True, \n",
    "    train=True, \n",
    "    transform = transform,\n",
    "    target_transform = transforms.Lambda(lambda x: get_target_and_mask(x))\n",
    "))\n",
    "\n",
    "idx = (train_data._dataset.targets != mnist_class_anomaly)\n",
    "train_data._dataset.targets = train_data._dataset.targets[idx]\n",
    "train_data._dataset.data = train_data._dataset.data[idx]\n",
    "\n",
    "dataset_utility = torch.zeros(len(train_data), fuzzy_rules_count)\n",
    "dataset_utility = dataset_utility.to(device)\n",
    "dataset_utility.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загружаем тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = datasets.MNIST(\n",
    "    '~/.pytorch/MNIST_data/', \n",
    "    download=True, \n",
    "    train=False, \n",
    "    transform=transform, \n",
    "    target_transform = transforms.Lambda(lambda x: get_target_and_mask(x))\n",
    ")\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем итераторы датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    \n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data,_,idx in iter(train_loader):\n",
    "    R, C = 1, 2\n",
    "    plt.subplot(R, C, 1)\n",
    "    plt.title(idx[0].item())\n",
    "    plt.imshow(data[0].squeeze())\n",
    "    plt.subplot(R, C, 2)\n",
    "    plt.imshow(augmentation(data)[0].squeeze())\n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dim, kernels):\n",
    "        super(Encoder, self).__init__()\n",
    "                \n",
    "        self.latent = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=2, bias=False),\n",
    "            nn.BatchNorm2d(8, affine=False),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.SiLU(),  \n",
    "            nn.Conv2d(8, 16, kernel_size=2, bias=False),\n",
    "            nn.BatchNorm2d(16, affine=False),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.SiLU(),  \n",
    "            nn.Conv2d(16, 32, kernel_size=2, bias=False),\n",
    "            nn.BatchNorm2d(32, affine=False),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.SiLU(),  \n",
    "            nn.Conv2d(32, 64, kernel_size=2, bias=False),\n",
    "            nn.BatchNorm2d(64, affine=False),\n",
    "            nn.SiLU(),  \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64, latent_dim, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.latent(x)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "m = Encoder(latent_dim, kernels)\n",
    "inp = torch.rand(batch_size, 1, 28, 28)\n",
    "mu = m.forward(inp)\n",
    "mu.shape\n",
    "#summary(m, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FuzzyInferencer                          [256, 10]                 --\n",
       "├─Sequential: 1-1                        [256, 10]                 --\n",
       "│    └─FuzzyLayer: 2-1                   [256, 10]                 131\n",
       "==========================================================================================\n",
       "Total params: 131\n",
       "Trainable params: 90\n",
       "Non-trainable params: 41\n",
       "Total mult-adds (M): 0\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FuzzyInferencer(nn.Module):\n",
    "     def __init__(self, latent_dim, fuzzy_rules_count):\n",
    "        super(FuzzyInferencer, self).__init__()\n",
    "        #rscale = 10\n",
    "        #initial_centroids = rscale * np.zeros((fuzzy_rules_count, latent_dim))\n",
    "        #initial_scales = rscale * np.ones((fuzzy_rules_count, latent_dim))\n",
    "        #radius = 1\n",
    "        #center = 0.0\n",
    "        #theta = np.linspace(0, 2*np.pi, fuzzy_rules_count)[:-1]\n",
    "        #x = radius * np.cos(theta) + center\n",
    "        #y = radius * np.sin(theta) + center\n",
    "        #for i in range(fuzzy_rules_count):\n",
    "        #    initial_centroids[i][0] = rscale * (center + np.random.randn())  #x[i]\n",
    "        #    initial_centroids[i][1] = rscale * (center + np.random.randn()) #y[i]\n",
    "\n",
    "        #initial_centroids[fuzzy_rules_count-1][0] = rscale * center\n",
    "        #initial_centroids[fuzzy_rules_count-1][1] = rscale * center\n",
    "        #initial_scales[fuzzy_rules_count-1][0] = 1\n",
    "        #initial_scales[fuzzy_rules_count-1][1] = 1\n",
    "\n",
    "        self.fuzzy = nn.Sequential(\n",
    "            #FuzzyLayer.from_centers_and_scales(initial_centroids, initial_scales, trainable=False),\n",
    "            FuzzyLayer.from_dimensions(latent_dim, fuzzy_rules_count, trainable=True),\n",
    "        )\n",
    "        \n",
    "     def forward(self, mu):\n",
    "         return self.fuzzy(mu)\n",
    "     \n",
    "m = FuzzyInferencer(latent_dim, fuzzy_rules_count)\n",
    "#inp = torch.rand(batch_size, latent_dim)\n",
    "#mu = m.forward(inp)\n",
    "#mu.shape\n",
    "summary(m, input_size=(batch_size, latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FSVDD                                    [256, 3]                  --\n",
       "├─Encoder: 1-1                           [256, 3]                  --\n",
       "│    └─Sequential: 2-1                   [256, 3]                  --\n",
       "│    │    └─Conv2d: 3-1                  [256, 8, 27, 27]          32\n",
       "│    │    └─BatchNorm2d: 3-2             [256, 8, 27, 27]          --\n",
       "│    │    └─MaxPool2d: 3-3               [256, 8, 13, 13]          --\n",
       "│    │    └─SiLU: 3-4                    [256, 8, 13, 13]          --\n",
       "│    │    └─Conv2d: 3-5                  [256, 16, 12, 12]         512\n",
       "│    │    └─BatchNorm2d: 3-6             [256, 16, 12, 12]         --\n",
       "│    │    └─MaxPool2d: 3-7               [256, 16, 6, 6]           --\n",
       "│    │    └─SiLU: 3-8                    [256, 16, 6, 6]           --\n",
       "│    │    └─Conv2d: 3-9                  [256, 32, 5, 5]           2,048\n",
       "│    │    └─BatchNorm2d: 3-10            [256, 32, 5, 5]           --\n",
       "│    │    └─MaxPool2d: 3-11              [256, 32, 2, 2]           --\n",
       "│    │    └─SiLU: 3-12                   [256, 32, 2, 2]           --\n",
       "│    │    └─Conv2d: 3-13                 [256, 64, 1, 1]           8,192\n",
       "│    │    └─BatchNorm2d: 3-14            [256, 64, 1, 1]           --\n",
       "│    │    └─SiLU: 3-15                   [256, 64, 1, 1]           --\n",
       "│    │    └─Flatten: 3-16                [256, 64]                 --\n",
       "│    │    └─Linear: 3-17                 [256, 3]                  192\n",
       "├─FuzzyInferencer: 1-2                   [256, 10]                 --\n",
       "│    └─Sequential: 2-2                   [256, 10]                 --\n",
       "│    │    └─FuzzyLayer: 3-18             [256, 10]                 131\n",
       "==========================================================================================\n",
       "Total params: 11,107\n",
       "Trainable params: 11,066\n",
       "Non-trainable params: 41\n",
       "Total mult-adds (M): 40.10\n",
       "==========================================================================================\n",
       "Input size (MB): 0.80\n",
       "Forward/backward pass size (MB): 18.44\n",
       "Params size (MB): 0.04\n",
       "Estimated Total Size (MB): 19.28\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FSVDD (nn.Module):\n",
    "    def __init__(self, latent_dim, fuzzy_rules_count, kernels):\n",
    "        super(FSVDD, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(latent_dim, kernels)\n",
    "        self.fuzzy =  FuzzyInferencer(latent_dim, fuzzy_rules_count)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        mu = self.encoder(x)\n",
    "        fz = self.fuzzy(mu)\n",
    "        \n",
    "        return mu, fz\n",
    "    \n",
    "m = FSVDD(latent_dim, fuzzy_rules_count, kernels)\n",
    "#inp = torch.rand(10, fuzzy_rules_count)\n",
    "#mu = m.forward(inp)\n",
    "#mu[0].shape\n",
    "summary(m, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 11,066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FSVDD(\n",
       "  (encoder): Encoder(\n",
       "    (latent): Sequential(\n",
       "      (0): Conv2d(1, 8, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (3): SiLU()\n",
       "      (4): Conv2d(8, 16, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "      (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (7): SiLU()\n",
       "      (8): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "      (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (11): SiLU()\n",
       "      (12): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "      (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
       "      (14): SiLU()\n",
       "      (15): Flatten(start_dim=1, end_dim=-1)\n",
       "      (16): Linear(in_features=64, out_features=3, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fuzzy): FuzzyInferencer(\n",
       "    (fuzzy): Sequential(\n",
       "      (0): FuzzyLayer(\n",
       "        (rots): ParameterList(\n",
       "            (0): Parameter containing: [torch.float32 of size 10x2 (cuda:0)]\n",
       "            (1): Parameter containing: [torch.float32 of size 10x1 (cuda:0)]\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FSVDD(latent_dim=latent_dim, fuzzy_rules_count=fuzzy_rules_count, kernels=kernels).to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Number of parameters: {num_params:,}')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ae_loss(x, recon_x):\n",
    "    loss_recon = (1 - ssim(recon_x, x))\n",
    "    return loss_recon.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_fz_loss(fz, act_thresh):\n",
    "    fz_mx = fz.max(-1)\n",
    "    mx_vals = fz_mx.values.reshape(-1, 1).repeat(1, fz.shape[1])\n",
    "    target = torch.zeros_like(fz)\n",
    "    target = torch.scatter(target, 1, fz_mx.indices.reshape(-1, 1), 1)\n",
    "    target = torch.where(mx_vals > act_thresh, target, 1)\n",
    "    target = target.detach()\n",
    "\n",
    "    return (target - fz).square().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utilities_by_input_vs_centroid_similarity(model, data):\n",
    "    inp_batch_size = data.shape[0]\n",
    "    act_fz = model.fuzzy.fuzzy[0].get_centroids().detach()#torch.diag(torch.ones(fuzzy_rules_count)).to(device)\n",
    "    raw_inferences = model.decoder_pass(act_fz)\n",
    "\n",
    "    rimgs = data.repeat_interleave(fuzzy_rules_count, dim=0)\n",
    "    rdfz = raw_inferences.repeat(inp_batch_size, 1, 1, 1)\n",
    "    \n",
    "    utilities = ssim(rdfz, rimgs).reshape(-1, fuzzy_rules_count)\n",
    "\n",
    "    #utilities = torch.where(utilities > 0.8, 1e+1, utilities)\n",
    "\n",
    "    return utilities\n",
    "    \n",
    "def compute_cfr_loss(fz, utilities):\n",
    "    \n",
    "    fz_util_tmp = (fz * utilities).sum(-1)\n",
    "    fz_sum = fz.sum(-1)\n",
    "\n",
    "    u_x = torch.where(fz_sum.abs() > 1e-20, fz_util_tmp/fz_sum, fz_util_tmp).reshape(-1, 1)\n",
    "\n",
    "    regret = utilities - u_x\n",
    "    zeros = torch.zeros_like(regret)\n",
    "    regret = torch.maximum(regret, zeros)\n",
    "    regret_sum = regret.sum(-1).reshape(-1, 1).repeat(1, fuzzy_rules_count)\n",
    "    fz_upd = torch.where(regret_sum > 0, regret/regret_sum, 1/fuzzy_rules_count)\n",
    "    \n",
    "    fz_upd = fz_upd.detach()\n",
    "    loss_fz = (fz_upd - fz).square().sum(-1).mean()\n",
    "    \n",
    "    return loss_fz, fz_upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fzsum_loss(fz):\n",
    "    return (1 - fz.sum(-1)).square().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_term_volume_loss(layer, target_volume):\n",
    "    ev = layer.get_transformation_matrix_eigenvals().real.min(-1).values\n",
    "    ev = (target_volume - ev).square().mean()\n",
    "    return ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_eigenvals_positive_loss(layer, eps = 1e-15):\n",
    "    ev = layer.get_transformation_matrix_eigenvals().real.min()\n",
    "    ev = torch.clamp(ev, max=eps)\n",
    "    return -ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arate(model, inp):\n",
    "    mu, fz = model.forward(inp)\n",
    "    #centroids = model.fuzzy.fuzzy[0].get_centroids().detach()\n",
    "    #d = torch.cdist(mu, centroids).min(-1).values\n",
    "    return fz.max(-1).values.cpu().numpy()# #(1 - ssim(x_recon.clamp(0, 1), inp)).cpu().numpy()#xent_continuous_ber((x_recon + 1)/2, (inp + 1)/2).cpu().numpy()# #ssim((inp + 1)/2, (recon_x+1)/2).cpu().numpy() #fz.sum(-1).cpu().numpy()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def train(model, dataloader, optimizer, sched, prev_updates, epoch, writer=None):\n",
    "    model.train()  \n",
    "    #model.fuzzy.fuzzy.eval()\n",
    "    #model.fuzzy.fuzzy[0].set_requires_grad_rot(False)\n",
    "    #model.fuzzy.fuzzy[0].set_requires_grad_scales(False)\n",
    "    for batch_idx, (data, _, item_idx) in enumerate(tqdm(dataloader, disable=True)):\n",
    "        n_upd = prev_updates + batch_idx\n",
    "        \n",
    "        data = data.to(device)\n",
    "        adata = augmentation(data)\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "\n",
    "        mu, fz = model(adata)  \n",
    "\n",
    "        u = dataset_utility[item_idx]\n",
    "        #loss_v =    fuzzy_term_volume_loss(model.fuzzy.fuzzy[0])\n",
    "        loss_cfr, fz_upd = compute_cfr_loss(fz, u)\n",
    "        \n",
    "        loss_vol = fuzzy_term_volume_loss(model.fuzzy.fuzzy[0], 1)\n",
    "        #loss_fz = (1 - fz.max(-1).values).clamp(max=0.8).square().mean() + fuzzy_term_volume_loss(model.fuzzy.fuzzy[0], 10)#+ (1 - fz.sum(-1)).square().mean() \n",
    "        #if(fz.sum(-1).mean() > 1):\n",
    "        #    loss_fz += fuzzy_term_volume_loss(model.fuzzy.fuzzy[0])\n",
    "            #centroids = model.fuzzy.fuzzy[0].get_centroids()\n",
    "            #avg_d = torch.cdist(centroids, centroids).mean(-1).sum()\n",
    "            #loss_fz += 1 / (avg_d + 1e-7)\n",
    "\n",
    "        #loss_vol = fuzzy_term_volume_loss(model.fuzzy.fuzzy[0])\n",
    "        #loss_fz_sum = compute_fzsum_loss(fz)\n",
    "\n",
    "        #x_reconstruct = model.decoder_pass(mu)\n",
    "        #loss_reconstruct = compute_ae_loss(data, x_reconstruct)\n",
    "        \n",
    "        ev_loss = keep_eigenvals_positive_loss(model.fuzzy.fuzzy[0])\n",
    "        if ev_loss.item() > 0:\n",
    "            print(\"EV trouble\")\n",
    "            ev_loss.backward(retain_graph=True)\n",
    "\n",
    "        (loss_cfr + loss_vol).backward()\n",
    "        #loss_cfr.backward()\n",
    "        \n",
    "        optimizer.step()  \n",
    "        \n",
    "        dataset_utility[item_idx] += fz.detach() #1e-2 * F.one_hot(fz.max(-1).indices, fuzzy_rules_count)\n",
    "\n",
    "        if sched is not None:\n",
    "            sched.step()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.12)    \n",
    "        \n",
    "    if writer is not None:\n",
    "        writer.add_scalar('FSVDD/LR', get_lr(optimizer), global_step=epoch)\n",
    "        \n",
    "    return prev_updates + len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, cur_step, epoch, writer=None):\n",
    "    model.eval() \n",
    "\n",
    "    test_recon_loss = 0\n",
    "    test_fz_vol = 0\n",
    "    test_fz_sum = 0\n",
    "    \n",
    "    lab_true = []\n",
    "    lab_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, lab in tqdm(test_loader, desc='Test MNIST', disable=True):\n",
    "            data = data.to(device)\n",
    "            rates = get_arate(model, data)\n",
    "            \n",
    "            for f, l in  zip(rates, lab):\n",
    "                lab_pred.append(f)        \n",
    "                if l == mnist_class_anomaly:\n",
    "                    lab_true.append(1)\n",
    "                else:\n",
    "                    lab_true.append(0)\n",
    "                        \n",
    "    fpr, tpr, _ = metrics.roc_curve(lab_true, lab_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    embedings = []\n",
    "    labels_expected = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(dataloader, desc='Testing', disable=True):\n",
    "            data = data.to(device)\n",
    "\n",
    "            mu, fz = model(data)  \n",
    "            \n",
    "            embedings.append(mu.cpu().numpy())\n",
    "            labels_expected.append((target == mnist_class_anomaly).cpu().numpy())\n",
    "\n",
    "            #loss_recon = compute_ae_loss(data, recon_x)\n",
    "            \n",
    "            fz_vol = fuzzy_term_volume_loss(model.fuzzy.fuzzy[0], 0)\n",
    "            fz_sum = fz.sum(-1).mean()\n",
    "            \n",
    "            #test_recon_loss += loss_recon.item()\n",
    "            test_fz_vol += fz_vol.item()\n",
    "            test_fz_sum += fz_sum.item()\n",
    "            \n",
    "    embedings = np.concatenate(embedings, axis=0)\n",
    "    labels_expected = np.concatenate(labels_expected, axis=0)\n",
    "   \n",
    "    test_recon_loss /= len(dataloader)\n",
    "    test_fz_vol /= len(dataloader)\n",
    "    test_fz_sum /= len(dataloader)\n",
    "    \n",
    "    print(f'[{cur_step}] Reconstruction loss: {test_recon_loss:.4f}, VOL: {test_fz_vol:.4f} SUM: {test_fz_sum:.2f} AUC: {roc_auc:.4f}')\n",
    "    \n",
    "    if writer is not None:\n",
    "        writer.add_scalar('FSVDD/AUC', roc_auc, global_step=cur_step)\n",
    "        #writer.add_scalar('FAE/Reconstruction', test_recon_loss, global_step=cur_step)\n",
    "        writer.add_scalar('FSVDD/Volume', test_fz_vol, global_step=cur_step)\n",
    "        writer.add_scalar('FSVDD/Sum', test_fz_sum, global_step=cur_step)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2, figsize=(9, 4))\n",
    "        centroids_c = model.fuzzy.fuzzy[0].get_centroids().detach().cpu().numpy()\n",
    "        \n",
    "        ax[0].scatter(embedings[:, 0],      embedings[:,  1], c=labels_expected, cmap=binary_cmap, s=2)\n",
    "        ax[0].scatter(centroids_c[:, 0],      centroids_c[:, 1], marker='1', c='green', s= 50)\n",
    "        \n",
    "        #ax[0].set_xlim(-1, 1)\n",
    "        #ax[0].set_ylim(-1, 1)\n",
    "        \n",
    "        ax[1].scatter(embedings[:, 0],      embedings[:,  2], c=labels_expected, cmap=binary_cmap, s=2)\n",
    "        ax[1].scatter(centroids_c[:, 0],      centroids_c[:, 2], marker='1', c='green', s= 50)\n",
    "        \n",
    "        #ax[1].set_xlim(-1, 1)\n",
    "        #ax[1].set_ylim(-1, 1)\n",
    "        \n",
    "        #act_fz = model.fuzzy.fuzzy[0].get_centroids().detach()#torch.diag(torch.ones(fuzzy_rules_count)).to(device)#\n",
    "        #samples = model.decoder_pass(act_fz)\n",
    "        # img_idx = 0\n",
    "        # fign, axn = plt.subplots(8, 1 + fuzzy_rules_count//8, figsize=(1 + fuzzy_rules_count//8, 8), squeeze=False)\n",
    "        # for i in range(8):\n",
    "        #     if img_idx >= fuzzy_rules_count:\n",
    "        #         continue\n",
    "        #     for j in range(fuzzy_rules_count//8):\n",
    "        #         axn[i, j].imshow(samples[img_idx].view(28, 28).cpu().detach().numpy(), cmap='gray')\n",
    "        #         axn[i, j].axis('off')\n",
    "        #         img_idx += 1\n",
    "\n",
    "        writer.add_figure('FSVDD/Emedding', fig, global_step=cur_step)\n",
    "        #writer.add_figure('FSVDD/Samples', fign, global_step=cur_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.5)\n",
    "#sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, learning_rate, epochs=num_epochs, steps_per_epoch=len(train_loader))\n",
    "#sched = torch.optim.lr_scheduler.ConstantLR(optimizer, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_updates = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[212] Reconstruction loss: 0.0000, VOL: 0.9582 SUM: 1.44 AUC: 0.6664\n",
      "[424] Reconstruction loss: 0.0000, VOL: 0.9685 SUM: 1.41 AUC: 0.6552\n",
      "[636] Reconstruction loss: 0.0000, VOL: 0.9635 SUM: 1.38 AUC: 0.5577\n",
      "[848] Reconstruction loss: 0.0000, VOL: 0.9435 SUM: 1.40 AUC: 0.5537\n",
      "[1060] Reconstruction loss: 0.0000, VOL: 0.9317 SUM: 1.42 AUC: 0.5318\n",
      "[1272] Reconstruction loss: 0.0000, VOL: 0.9274 SUM: 1.39 AUC: 0.5232\n",
      "[1484] Reconstruction loss: 0.0000, VOL: 0.9229 SUM: 1.37 AUC: 0.5262\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    prev_updates = train(model, train_loader, optimizer, None, prev_updates, epoch, writer=writer)\n",
    "    test(model, test_loader, prev_updates, epoch, writer=writer)\n",
    "    scheduler.step()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_eigenvals_positive_loss(model.fuzzy.fuzzy[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализируем результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import IsolationForest\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import ConfusionMatrixDisplay\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# train_x = []\n",
    "# test_x = []\n",
    "# test_y = []\n",
    "# with torch.no_grad():\n",
    "#     for _, (data, _) in enumerate(tqdm(train_loader)):\n",
    "#         data = data.to(device)\n",
    "#         fz, _, _ = model.forward(data)\n",
    "#         for f in fz:\n",
    "#             train_x.append(f.cpu().numpy())\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for _, (data, target) in enumerate(tqdm(test_loader)):\n",
    "#         data = data.to(device)\n",
    "#         fz, _, _  = model.forward(data)\n",
    "#         for f, trg in zip(fz, target):\n",
    "#             test_x.append(f.cpu().numpy())\n",
    "#             if trg == mnist_class_anomaly:\n",
    "#                 test_y.append(-1)\n",
    "#             else:\n",
    "#                 test_y.append(1)\n",
    "    \n",
    "# clf = IsolationForest(random_state=0, n_estimators=1000).fit(train_x)\n",
    "# y_pred =clf.predict(test_x)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix(test_y, y_pred))\n",
    "# disp.plot()\n",
    "# accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_activation_stats_by_digit(digit, model, dataloader):\n",
    "    rulestat = {}\n",
    "    with torch.no_grad():\n",
    "        for _, (data, target) in enumerate(tqdm(dataloader)):\n",
    "        \n",
    "            data = data.to(device)\n",
    "            _, fz, _ = model.forward(data)\n",
    "            act_fz = fz.max(-1).indices.cpu().numpy()\n",
    "            for ind, trg in zip(act_fz, target):\n",
    "                if trg == digit:\n",
    "                    rulestat[ind] = rulestat.get(ind, 0) + 1\n",
    "    return rulestat\n",
    "\n",
    "\n",
    "test_stat_by_digit = get_activation_stats_by_digit(9, model, test_loader)\n",
    "\n",
    "plt.bar(list(test_stat_by_digit.keys()), test_stat_by_digit.values(), 0.5, color='r')\n",
    "plt.xlim((-1, fuzzy_rules_count + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat_by_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn(64, latent_dim).to(device)\n",
    "samples = model.decoder_pass(z)\n",
    "\n",
    "# Plot the generated images\n",
    "fig, ax = plt.subplots(8, 8, figsize=(8, 8))\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        ax[i, j].imshow(samples[i*8+j].view(28, 28).cpu().detach().numpy(), cmap='gray')\n",
    "        ax[i, j].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fz = torch.zeros(64, fuzzy_rules_count).to(device)\n",
    "# for i in range(64):\n",
    "#     fz[i][5] = 1.0/(i+1)\n",
    "\n",
    "# samples = model.decoder.decode_from_fz(fz)\n",
    "\n",
    "# # Plot the generated images\n",
    "# fig, ax = plt.subplots(8, 8, figsize=(8, 8))\n",
    "# for i in range(8):\n",
    "#     for j in range(8):\n",
    "#         ax[i, j].imshow(samples[i*8+j].view(28, 28).cpu().detach().numpy(), cmap='gray')\n",
    "#         ax[i, j].axis('off')\n",
    "\n",
    "# # plt.show()\n",
    "# plt.savefig('cvae_mnist.webp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim = piqa.SSIM(window_size = 9, n_channels=1, reduction='none').to(device)\n",
    "def get_arate(inp):\n",
    "    mu, fz_1, x_recon = model.forward(inp)\n",
    "    #_, x_recon, fz_2 = model.forward(x_recon)\n",
    "    \n",
    "    return (1 - ssim(x_recon.clamp(0, 1), inp)).cpu().numpy() #(1 - ssim((x_recon + 1)/2, (inp + 1)/2)).cpu().numpy()#xent_continuous_ber((x_recon + 1)/2, (inp + 1)/2).cpu().numpy()# (1 - ssim((x_recon + 1)/2, (inp + 1)/2)).cpu().numpy() #ssim((inp + 1)/2, (recon_x+1)/2).cpu().numpy() #fz.sum(-1).cpu().numpy()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firings_mnist = {}\n",
    "firings_mnist['MNIST'] = []\n",
    "firings_mnist['DISSIDENT'] = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader, desc='MNIST HIST'):\n",
    "        data = data.view((-1,1,28,28)).to(device)\n",
    "        rates = get_arate(data)\n",
    "        for f, l in  zip(rates, target):\n",
    "            if l != mnist_class_anomaly:\n",
    "                firings_mnist['MNIST'].append(f)\n",
    "            else:\n",
    "                firings_mnist['DISSIDENT'].append(f)\n",
    "        \n",
    "\n",
    "labels, data = firings_mnist.keys(), firings_mnist.values()\n",
    "\n",
    "fig = plt.figure(figsize =(12, 2))\n",
    "plt.boxplot(data, notch=True, showfliers=False)\n",
    "plt.xticks(range(1, len(labels) + 1), labels)\n",
    "plt.show()\n",
    "\n",
    "writer.add_figure('Anomaly Detection', fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    firing_levels = []\n",
    "    lab_true = []\n",
    "    lab_pred = []\n",
    "\n",
    "    for data, lab in tqdm(test_loader, desc='Test MNIST', disable=True):\n",
    "        data = data.view((-1,1,28,28)).to(device)\n",
    "        rates = get_arate(data)\n",
    "        \n",
    "        for f, l in  zip(rates, lab):\n",
    "            firing_levels.append(f)\n",
    "            lab_pred.append(f)        \n",
    "            if l == mnist_class_anomaly:\n",
    "                lab_true.append(1)\n",
    "            else:\n",
    "                lab_true.append(0)\n",
    "                    \n",
    "    fpr, tpr, threshold = metrics.roc_curve(lab_true, lab_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    fig = plt.figure(figsize =(4, 4))\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    writer.add_figure('ROC', fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot():\n",
    "    embedings = []\n",
    "    labels_expected = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc='Encoding'):\n",
    "            data = data.view((-1,1,28,28)).to(device)\n",
    "            embeding,_,_ = model.forward(data)\n",
    "            embedings.append(embeding.cpu().numpy())\n",
    "            labels_expected.append(target.cpu().numpy())\n",
    "    embedings = np.concatenate(embedings, axis=0)\n",
    "    labels_expected = np.concatenate(labels_expected, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    R, C = 1, 3\n",
    "\n",
    "    plt.subplot(R, C, 1)\n",
    "    plt.title(\"MNIST XY\")\n",
    "    plt.scatter(embedings[:, 0],      embedings[:,  1], c=labels_expected, cmap='tab10', s=2)\n",
    "    #plt.scatter(centroids[:, 0],      centroids[:, 1], marker='1', c='black', s= 50)\n",
    "\n",
    "    plt.subplot(R, C, 2)\n",
    "    plt.title(\"MNIST XZ\")\n",
    "    plt.scatter(embedings[:, 0],      embedings[:,  2], c=labels_expected, cmap='tab10', s=2)\n",
    "    #plt.scatter(centroids[:, 0],      centroids[:, 2], marker='1', c='black', s= 50)\n",
    "\n",
    "    \n",
    "show_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_item_reconstructio(ind):\n",
    "    for data, trg in iter(test_loader):\n",
    "        data = data.to(device)\n",
    "        _, fz, x_rec = model.forward(data)\n",
    "        #_, x_rec_2, fz_2 = model.forward(x_rec)\n",
    "\n",
    "        plt.figure(figsize=(24, 6))\n",
    "\n",
    "        R, C = 1, 6\n",
    "\n",
    "        #plt.subplot(R, C, 1)\n",
    "        #plt.imshow(fz[ind].detach().cpu().squeeze())\n",
    "        #plt.bar(range(fuzzy_rules_count), fz[ind].detach().cpu().numpy(), color='g')\n",
    "        #plt.bar(range(fuzzy_rules_count), fz_2[ind].detach().cpu().numpy(), color='r')\n",
    "        plt.subplot(R, C, 1)\n",
    "        plt.imshow(data[ind].cpu().squeeze())\n",
    "        plt.subplot(R, C, 2)\n",
    "        plt.imshow(x_rec[ind].detach().cpu().squeeze())\n",
    "        #plt.subplot(R, C, 3)\n",
    "        #plt.imshow(x_rec_2[ind].detach().cpu().squeeze())\n",
    "        plt.subplot(R, C, 3)\n",
    "        plt.imshow((x_rec[ind] - data[ind]).abs().detach().cpu().squeeze())\n",
    "        #plt.subplot(R, C, 4)\n",
    "        #plt.imshow(((data[ind]-x_rec[ind]).abs() - x_resd[ind]).abs().clamp(min=0.2).abs().detach().cpu().squeeze())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_item_reconstructio(4)\n",
    "show_item_reconstructio(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
