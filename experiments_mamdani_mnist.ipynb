{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moister/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import tqdm\n",
    "from torchfuzzy import FuzzyLayer, DefuzzyLinearLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-2\n",
    "labels_count = 10\n",
    "num_epochs = 20\n",
    "fuzzy_dim = 2\n",
    "fuzzy_rules_count = 10\n",
    "\n",
    "prefix = \"mamdani_mnist\"\n",
    "writer = SummaryWriter(f'runs/mnist/{prefix}_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp = torch.rand((10,3))\n",
    "# df = DefuzzyLinearLayer.from_dimensions(3, 2)\n",
    "# df.forward(inp),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: x.view(-1, 28, 28) - 0.5),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(target_label):\n",
    "    \"\"\"\n",
    "    Возвращает вектор целевого значения\n",
    "\n",
    "    Args:\n",
    "        target_label (int): Метка класса\n",
    "    \n",
    "    Returns:\n",
    "        tensor (1, 10)\n",
    "    \"\"\"\n",
    "    t = F.one_hot(torch.LongTensor([target_label]), labels_count)\n",
    "    return t.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем обучающую выборку\n",
    "train_data = datasets.MNIST(\n",
    "    '~/.pytorch/MNIST_data/', \n",
    "    download=True, \n",
    "    train=True, \n",
    "    transform = transform,\n",
    "    target_transform = transforms.Lambda(lambda x: get_target(x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загружаем тестовую выборку\n",
    "test_data = datasets.MNIST(\n",
    "    '~/.pytorch/MNIST_data/', \n",
    "    download=True, \n",
    "    train=False, \n",
    "    transform=transform, \n",
    "    target_transform = transforms.Lambda(lambda x: get_target(x))\n",
    ")\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем итераторы датасетов\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    \n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Компонент энкодера\n",
    "    \n",
    "    Args:\n",
    "        fuzzy_dim (int): Размер латентного вектора.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fuzzy_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "                \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=5),\n",
    "            nn.SiLU(),  \n",
    "            nn.Conv2d(8, 16, kernel_size=5),\n",
    "            nn.SiLU(),  \n",
    "            nn.Conv2d(16, 32, kernel_size=5),\n",
    "            nn.SiLU(),  \n",
    "            nn.Conv2d(32, 64, kernel_size=5),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.SiLU(),  \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 625),\n",
    "            nn.BatchNorm1d(625),\n",
    "            nn.SiLU(),  \n",
    "            nn.Linear(625, fuzzy_dim),\n",
    "        )\n",
    "         \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Выход энкодера\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Входной вектор.\n",
    "        \n",
    "        Returns:\n",
    "            encoded input\n",
    "        \"\"\"\n",
    "\n",
    "        ex = self.encoder(x)\n",
    "        \n",
    "        return ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MamdaniFIS(nn.Module):\n",
    "    \"\"\"\n",
    "    MamdaniFIS\n",
    "    \n",
    "    Args:\n",
    "        fuzzy_dim (int): Размер латентного вектора.\n",
    "        labels_count (int): Количество выходов классификатора\n",
    "    \"\"\"\n",
    "    def __init__(self, fuzzy_dim, fuzzy_rules_count, labels_count):\n",
    "        super(MamdaniFIS, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(fuzzy_dim)        \n",
    "        \n",
    "        self.fuzzy = nn.Sequential(\n",
    "            FuzzyLayer.from_dimensions(fuzzy_dim, fuzzy_rules_count, trainable=True),\n",
    "            DefuzzyLinearLayer.from_dimensions(fuzzy_rules_count, labels_count)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Входной вектор.\n",
    "        \n",
    "        Returns:\n",
    "            labels\n",
    "        \"\"\"\n",
    "\n",
    "        ex = self.encoder(x)\n",
    "        labels = self.fuzzy(ex)\n",
    "\n",
    "        return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(target_labels, predicted_labels):\n",
    "    \n",
    "    #print(torch.squeeze(target_labels,1))\n",
    "    #print(predicted_labels)\n",
    "    ceLoss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    loss_fuzzy = ceLoss.forward(predicted_labels, torch.squeeze(target_labels,1).float())\n",
    "\n",
    "    return loss_fuzzy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 5,830,935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MamdaniFIS(\n",
       "  (encoder): Encoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (1): SiLU()\n",
       "      (2): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (3): SiLU()\n",
       "      (4): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (5): SiLU()\n",
       "      (6): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
       "      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): SiLU()\n",
       "      (9): Flatten(start_dim=1, end_dim=-1)\n",
       "      (10): Linear(in_features=9216, out_features=625, bias=True)\n",
       "      (11): BatchNorm1d(625, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (12): SiLU()\n",
       "      (13): Linear(in_features=625, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fuzzy): Sequential(\n",
       "    (0): FuzzyLayer()\n",
       "    (1): DefuzzyLinearLayer()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MamdaniFIS(fuzzy_dim, fuzzy_rules_count, labels_count).to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Number of parameters: {num_params:,}')\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, prev_updates, writer=None):\n",
    "    model.train()  \n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(tqdm(dataloader)):\n",
    "        n_upd = prev_updates + batch_idx\n",
    "        \n",
    "        data = data.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "        \n",
    "        labels = model.forward(data)  \n",
    "        \n",
    "        loss = compute_loss(target, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if n_upd % 100 == 0:\n",
    "            total_norm = 0.0\n",
    "            for p in model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    param_norm = p.grad.data.norm(2)\n",
    "                    total_norm += param_norm.item() ** 2\n",
    "            total_norm = total_norm ** (1. / 2)\n",
    "        \n",
    "            print(f'Step {n_upd:,} (N samples: {n_upd*batch_size:,}), Loss: {loss.item():.4f} Grad: {total_norm:.4f}')\n",
    "\n",
    "            if writer is not None:\n",
    "                global_step = n_upd\n",
    "                writer.add_scalar('Loss/Train', loss.item(), global_step)\n",
    "                writer.add_scalar('GradNorm/Train', total_norm, global_step)\n",
    "            \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)    \n",
    "        \n",
    "        optimizer.step()  \n",
    "        \n",
    "    return prev_updates + len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, cur_step, writer=None):\n",
    "    model.eval() \n",
    "    test_loss = 0\n",
    "    test_accuracy = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(dataloader, desc='Testing'):\n",
    "            data = data.to(device)\n",
    "            \n",
    "            labels = model.forward(data)  \n",
    "            \n",
    "            loss = compute_loss(target, labels)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            pred_target = np.argmax(labels.cpu().numpy(), axis=1)\n",
    "            target_labels =  np.argmax(torch.squeeze(target,1).cpu().numpy(), axis=1)\n",
    "            test_accuracy += np.sum(target_labels==pred_target) / len(pred_target)\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    test_accuracy /= len(dataloader)\n",
    "\n",
    "    print(f'====> Test set loss: {test_loss:.4f} (Accuracy {test_accuracy:.4f})')\n",
    "    \n",
    "    if writer is not None:\n",
    "        writer.add_scalar('Loss/Test', test_loss, global_step=cur_step)\n",
    "        writer.add_scalar('Fuzzy/Test/Accuracy', test_accuracy, global_step=cur_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/235 [00:01<04:25,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 (N samples: 0), Loss: 2.3049 Grad: 0.5766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 104/235 [00:42<00:06, 20.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 (N samples: 25,600), Loss: 2.1859 Grad: 0.2704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 203/235 [00:47<00:01, 21.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200 (N samples: 51,200), Loss: 2.1533 Grad: 0.3713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:48<00:00,  4.85it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 26.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 2.1466 (Accuracy 0.3293)\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 69/235 [00:03<00:07, 22.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 300 (N samples: 76,800), Loss: 2.1230 Grad: 0.4119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 168/235 [00:07<00:03, 21.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400 (N samples: 102,400), Loss: 2.0593 Grad: 0.4149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:10<00:00, 21.92it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 26.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 2.0414 (Accuracy 0.3630)\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 33/235 [00:01<00:09, 20.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 (N samples: 128,000), Loss: 2.0306 Grad: 0.4012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 135/235 [00:06<00:04, 21.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600 (N samples: 153,600), Loss: 1.9975 Grad: 0.3501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:10<00:00, 21.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 700 (N samples: 179,200), Loss: 1.9888 Grad: 0.3375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 25.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.9744 (Accuracy 0.4573)\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 99/235 [00:04<00:06, 22.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800 (N samples: 204,800), Loss: 1.9660 Grad: 0.4300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 198/235 [00:08<00:01, 21.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 900 (N samples: 230,400), Loss: 1.9201 Grad: 0.3927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:10<00:00, 22.15it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 26.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.9310 (Accuracy 0.4745)\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 63/235 [00:02<00:07, 22.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,000 (N samples: 256,000), Loss: 1.9049 Grad: 0.4731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 165/235 [00:07<00:03, 21.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,100 (N samples: 281,600), Loss: 1.9117 Grad: 0.5157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:10<00:00, 22.05it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 26.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.8917 (Accuracy 0.4750)\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 30/235 [00:01<00:09, 20.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,200 (N samples: 307,200), Loss: 1.8994 Grad: 0.4752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 126/235 [00:17<01:11,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,300 (N samples: 332,800), Loss: 1.8658 Grad: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 229/235 [01:05<00:00, 19.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,400 (N samples: 358,400), Loss: 1.8560 Grad: 0.4827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [01:05<00:00,  3.58it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 24.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.8565 (Accuracy 0.4799)\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 93/235 [00:04<00:06, 21.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,500 (N samples: 384,000), Loss: 1.8604 Grad: 0.6064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 195/235 [00:09<00:01, 21.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,600 (N samples: 409,600), Loss: 1.8220 Grad: 0.5983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:10<00:00, 21.60it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 25.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.8263 (Accuracy 0.4824)\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 60/235 [00:02<00:08, 21.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,700 (N samples: 435,200), Loss: 1.8134 Grad: 0.4638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 159/235 [00:07<00:03, 21.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,800 (N samples: 460,800), Loss: 1.8018 Grad: 0.6606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:10<00:00, 21.45it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 24.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.7924 (Accuracy 0.4813)\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 24/235 [00:01<00:10, 20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1,900 (N samples: 486,400), Loss: 1.7806 Grad: 0.4027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 125/235 [00:06<00:05, 21.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,000 (N samples: 512,000), Loss: 1.7661 Grad: 0.4818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 224/235 [00:10<00:00, 21.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,100 (N samples: 537,600), Loss: 1.7599 Grad: 0.4732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.93it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 25.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.7696 (Accuracy 0.4757)\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 90/235 [00:04<00:06, 20.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,200 (N samples: 563,200), Loss: 1.7416 Grad: 0.6518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 189/235 [00:08<00:02, 22.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,300 (N samples: 588,800), Loss: 1.7335 Grad: 0.7924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:10<00:00, 21.69it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 24.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.7345 (Accuracy 0.4865)\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 53/235 [00:02<00:09, 19.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,400 (N samples: 614,400), Loss: 1.7366 Grad: 1.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 155/235 [00:07<00:03, 22.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,500 (N samples: 640,000), Loss: 1.7096 Grad: 0.6270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 21.31it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:25<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.7068 (Accuracy 0.4875)\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 16/235 [00:11<02:30,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,600 (N samples: 665,600), Loss: 1.7001 Grad: 0.6609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 119/235 [00:38<00:05, 20.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,700 (N samples: 691,200), Loss: 1.6770 Grad: 0.5719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 218/235 [00:43<00:00, 20.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,800 (N samples: 716,800), Loss: 1.6658 Grad: 0.7542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:44<00:00,  5.29it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 24.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.6804 (Accuracy 0.4889)\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 84/235 [00:03<00:07, 20.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2,900 (N samples: 742,400), Loss: 1.6632 Grad: 0.9679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 183/235 [00:08<00:02, 21.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,000 (N samples: 768,000), Loss: 1.6524 Grad: 0.4198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 21.07it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 24.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.6545 (Accuracy 0.4887)\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 49/235 [00:02<00:09, 20.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,100 (N samples: 793,600), Loss: 1.6602 Grad: 0.8268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 150/235 [00:07<00:03, 21.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,200 (N samples: 819,200), Loss: 1.6491 Grad: 1.2967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 20.92it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 26.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.6287 (Accuracy 0.4897)\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 15/235 [00:00<00:09, 22.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,300 (N samples: 844,800), Loss: 1.6377 Grad: 1.0742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 114/235 [00:05<00:05, 21.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,400 (N samples: 870,400), Loss: 1.6027 Grad: 0.5541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 213/235 [00:09<00:01, 21.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,500 (N samples: 896,000), Loss: 1.6031 Grad: 0.9794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:10<00:00, 21.58it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 25.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.6056 (Accuracy 0.4846)\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 78/235 [00:03<00:07, 21.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,600 (N samples: 921,600), Loss: 1.5885 Grad: 0.8852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 180/235 [00:08<00:02, 21.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,700 (N samples: 947,200), Loss: 1.5798 Grad: 0.5909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:10<00:00, 21.47it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 25.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.5806 (Accuracy 0.4921)\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 45/235 [00:02<00:08, 21.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,800 (N samples: 972,800), Loss: 1.5723 Grad: 1.3443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 141/235 [00:46<01:04,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3,900 (N samples: 998,400), Loss: 1.5393 Grad: 1.2679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [01:08<00:00,  3.43it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 24.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.5322 (Accuracy 0.4854)\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/235 [00:00<00:10, 21.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,000 (N samples: 1,024,000), Loss: 1.4978 Grad: 0.9914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 108/235 [00:05<00:06, 19.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,100 (N samples: 1,049,600), Loss: 1.5004 Grad: 1.0967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 210/235 [00:09<00:01, 20.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,200 (N samples: 1,075,200), Loss: 1.4760 Grad: 0.5114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:11<00:00, 21.22it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 25.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.5017 (Accuracy 0.4888)\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 74/235 [00:03<00:07, 21.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,300 (N samples: 1,100,800), Loss: 1.4789 Grad: 0.6330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 175/235 [00:08<00:02, 22.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,400 (N samples: 1,126,400), Loss: 1.4304 Grad: 0.6064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:10<00:00, 21.45it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 26.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.4756 (Accuracy 0.4909)\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 39/235 [00:01<00:08, 22.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,500 (N samples: 1,152,000), Loss: 1.4593 Grad: 0.5149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 140/235 [00:06<00:04, 22.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 4,600 (N samples: 1,177,600), Loss: 1.4760 Grad: 0.6516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:10<00:00, 21.74it/s]\n",
      "Testing: 100%|██████████| 40/40 [00:01<00:00, 25.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1.4567 (Accuracy 0.4874)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prev_updates = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    prev_updates = train(model, train_loader, optimizer, prev_updates, writer=writer)\n",
    "    test(model, test_loader, prev_updates, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
