{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Детектор аномалии на принципе многократной прогонки реконструкции входного образца до сходимости латентного вектора.\n",
    "Критерий аномальности - расстояние от первоначального латентного вектора до сошедшего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.auto import tqdm\n",
    "from torchfuzzy import FuzzyLayer, DefuzzyLinearLayer, FuzzyBellLayer\n",
    "import piqa\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.manifold import TSNE\n",
    "from torchvision.transforms import v2\n",
    "from torchinfo import summary\n",
    "from matplotlib.colors import ListedColormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 1e-2\n",
    "num_epochs = 100\n",
    "latent_dim = 3\n",
    "mnist_class_anomaly = 4\n",
    "kernels = 8\n",
    "fuzzy_rules_count = 18\n",
    "\n",
    "prefix = f\"fuzzy_ad\"\n",
    "writer = SummaryWriter(f'runs/mnist/{prefix}_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "binary_cmap = ListedColormap(['yellow', 'red'], N=2)\n",
    "ssim = piqa.SSIM(window_size = 11, n_channels=1, reduction='none').to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет\n",
    "\n",
    "1. Исключаем класс аномалии `mnist_class_anomaly` из общей выборк\n",
    "2. Убираем метки с остальных классов\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_and_transform(x):\n",
    "    nimg = x.view(-1, 28, 28)\n",
    "    nimg = torch.clamp(nimg, 0, 1)\n",
    "    return nimg\n",
    "\n",
    "def clamp(x):\n",
    "    #nimg = 2.0*(x.view(-1, 28, 28) - 0.5)\n",
    "    nimg = torch.clamp(x, 0, 1)\n",
    "    return nimg\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(norm_and_transform)\n",
    "])\n",
    "\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomRotation(25, fill=0), \n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), fill=0), \n",
    "    #transforms.RandomCrop(size=26),\n",
    "    #transforms.Resize(size=(28, 28)),\n",
    "    transforms.Lambda(clamp)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_and_mask(target_label):\n",
    "    t = target_label\n",
    "    return t \n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    '~/.pytorch/MNIST_data/', \n",
    "    download=True, \n",
    "    train=True, \n",
    "    transform = transform,\n",
    "    target_transform = transforms.Lambda(lambda x: get_target_and_mask(x))\n",
    ")\n",
    "\n",
    "idx = (train_data.targets != mnist_class_anomaly)\n",
    "train_data.targets = train_data.targets[idx]\n",
    "train_data.data = train_data.data[idx]\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "загружаем тестовую выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(\n",
    "    '~/.pytorch/MNIST_data/', \n",
    "    download=True, \n",
    "    train=False, \n",
    "    transform=transform, \n",
    "    target_transform = transforms.Lambda(lambda x: get_target_and_mask(x))\n",
    ")\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем итераторы датасетов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True,\n",
    "    \n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data,_ in iter(train_loader):\n",
    "    R, C = 1, 2\n",
    "    plt.subplot(R, C, 1)\n",
    "    plt.imshow(data[0].squeeze())\n",
    "    plt.subplot(R, C, 2)\n",
    "    plt.imshow(augmentation(data)[0].squeeze())\n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Компонент энкодера для VAE\n",
    "    \n",
    "    Args:\n",
    "        latent_dim (int): Размер латентного вектора.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, kernels):\n",
    "        super(Encoder, self).__init__()\n",
    "                \n",
    "        \n",
    "        self.latent = nn.Sequential(\n",
    "            nn.Conv2d(1, kernels, kernel_size = 5), \n",
    "            nn.Conv2d(kernels, kernels, kernel_size = 5), \n",
    "            nn.BatchNorm2d(kernels), \n",
    "            nn.SiLU(),\n",
    "\n",
    "            nn.Conv2d(kernels, 2*kernels, kernel_size = 5), \n",
    "            nn.Conv2d(2*kernels, 2*kernels, kernel_size = 5), \n",
    "            nn.BatchNorm2d(2*kernels), \n",
    "            nn.SiLU(),\n",
    "\n",
    "            nn.Conv2d(2*kernels, 4*kernels, kernel_size = 5), \n",
    "            nn.Conv2d(4*kernels, 4*kernels, kernel_size = 5), \n",
    "            nn.BatchNorm2d(4*kernels), \n",
    "            nn.SiLU(),\n",
    "\n",
    "            nn.Conv2d(4*kernels, 8*kernels, kernel_size = 4), \n",
    "            nn.BatchNorm2d(8*kernels), \n",
    "            nn.SiLU(),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8*kernels, 4*kernels), \n",
    "            nn.BatchNorm1d(4*kernels),\n",
    "            nn.SiLU(),\n",
    "\n",
    "            nn.Linear(4*kernels, 2*kernels), \n",
    "            nn.BatchNorm1d(2*kernels),\n",
    "            nn.SiLU(),\n",
    "\n",
    "            nn.Linear(2*kernels, latent_dim),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        initial_centroids = (0.5-np.random.rand(fuzzy_rules_count, latent_dim))\n",
    "        initial_scales =   np.ones((fuzzy_rules_count, latent_dim))\n",
    "\n",
    "        self.fuzzy_a = nn.Sequential(\n",
    "            FuzzyLayer.from_centers_and_scales(initial_centroids, initial_scales)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Выход энкодера для чистого VAE.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Входной вектор.\n",
    "            eps (float): Небольшая поправка к скейлу для лучшей сходимости и устойчивости.\n",
    "        \n",
    "        Returns:\n",
    "            mu, logvar, z, dist\n",
    "        \"\"\"\n",
    "        latent = self.latent(x)\n",
    "        #pt_a, pt_b = torch.chunk(latent, 2, dim=-1)\n",
    "        fz = self.fuzzy_a(latent)\n",
    "        #fz = (fz.clamp(min=0.1) - 0.1)/0.9\n",
    "        #fz_b = self.fuzzy_b(pt_b)\n",
    "        #fz = torch.cat((fz_a, fz_b),1)\n",
    "        #fz = 1 - fz\n",
    "        return fz, latent\n",
    "\n",
    "inp = torch.rand(10, 1, 28, 28)\n",
    "m = Encoder(latent_dim, 16)\n",
    "fz, mu = m.forward(inp)\n",
    "\n",
    "summary(m, input_size=(batch_size, 1, 28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Компонент декодера для VAE\n",
    "    \n",
    "    Args:\n",
    "        latent_dim (int): Размер латентного вектора.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fuzzy_rules_count, kernels):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.defuzzy = nn.Sequential(\n",
    "            DefuzzyLinearLayer.from_dimensions(fuzzy_rules_count, 28*28, with_norm=False),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "         \n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Декодирует латентный вектор в исходное представление\n",
    "        \n",
    "        Args:\n",
    "            z (torch.Tensor): Латентный вектор.\n",
    "        \n",
    "        Returns:\n",
    "            x\n",
    "        \"\"\"\n",
    "        out = self.defuzzy(z)\n",
    "        #out = out.clamp(0, 1)\n",
    "        out = out.reshape(-1, 1, 28, 28)\n",
    "        return out\n",
    "    \n",
    "inp = torch.rand(batch_size, fuzzy_rules_count)\n",
    "m = Decoder(fuzzy_rules_count, 16)\n",
    "mu = m.forward(inp)\n",
    "mu.shape\n",
    "\n",
    "summary(m, input_size=(batch_size, fuzzy_rules_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        latent_dim (int): Размер латентного вектора.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_dim, fuzzy_rules_count, kernels):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(latent_dim, kernels)        \n",
    "        self.decoder = Decoder(fuzzy_rules_count, kernels)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        fz, mu = self.encoder(x)\n",
    "        x_recon = self.decoder(fz)\n",
    "        \n",
    "        return fz, mu, x_recon\n",
    "    \n",
    "    def half_pass(self, x):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        fz, mu = self.encoder(x)\n",
    "        return fz, mu\n",
    "    \n",
    "    def decoder_pass(self, x):\n",
    "        r = self.decoder(x)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE(latent_dim=latent_dim, fuzzy_rules_count=fuzzy_rules_count, kernels=kernels).to(device)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Number of parameters: {num_params:,}')\n",
    "\n",
    "summary(model, input_size=(batch_size, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, learning_rate, epochs=num_epochs, steps_per_epoch=len(train_loader))\n",
    "sched = torch.optim.lr_scheduler.ConstantLR(optimizer, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ae_loss(x, recon_x):\n",
    "    #loss_c = ssim(x, centroid).clamp(0, 1).detach()\n",
    "    loss_recon = (1 - ssim(recon_x, x))#(x-recon_x).square()#\n",
    "    loss_recon = loss_recon.mean()\n",
    "    return loss_recon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fuzzy_loss(fz):\n",
    "\n",
    "    return (1 - fz.sum(-1)).square().mean() #(0.999 - (tops[:,0]+tops[:,1]).clamp(max=0.999)).mean() + tops[:, 2].clamp(min=0.001).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_eigenvals_positive_loss(layer, eps = 1e-15):\n",
    "    ev = layer.get_transformation_matrix_eigenvals().real.min()\n",
    "    ev = torch.clamp(ev, max=eps)\n",
    "    return -ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_term_volume_loss(layer, fz):\n",
    "    dfz = fz.detach().mean(0)\n",
    "    \n",
    "    ev = layer.get_transformation_matrix_eigenvals().real.mean(-1)\n",
    "    ev = 1/ev.mean()\n",
    "    \n",
    "    return ev#(1 - fz.max(-1).values).abs().mean()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arate(inp):\n",
    "    fz, mu, x_recon = model.forward(inp)\n",
    "    \n",
    "    return fz.sum(-1).cpu().numpy() #(1 - ssim(x_recon.clamp(0, 1), inp)).cpu().numpy()#xent_continuous_ber((x_recon + 1)/2, (inp + 1)/2).cpu().numpy()# #ssim((inp + 1)/2, (recon_x+1)/2).cpu().numpy() #fz.sum(-1).cpu().numpy()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def train(model, dataloader, optimizer, sched, prev_updates, epoch, writer=None):\n",
    "    model.train()  \n",
    "    \n",
    "    for batch_idx, (data, _) in enumerate(tqdm(dataloader, disable=True)):\n",
    "        n_upd = prev_updates + batch_idx\n",
    "        \n",
    "        data = data.to(device)\n",
    "        adata = augmentation(data)\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "        \n",
    "        fz, mu = model.half_pass(adata)  \n",
    "        x_reconstruct = model.decoder_pass(fz)\n",
    "        #x_centroidal = model.decoder(F.one_hot(fz.argmax(-1), fuzzy_rules_count).float())\n",
    "        \n",
    "        loss_reconstruct = compute_ae_loss(data, x_reconstruct)\n",
    "        \n",
    "        #fz_loss = fuzzy_term_volume_loss(model.encoder.fuzzy_a[0], fz)\n",
    "        \n",
    "        ev_loss = keep_eigenvals_positive_loss(model.encoder.fuzzy_a[0])\n",
    "        if ev_loss.item() > 0:\n",
    "            ev_loss.backward(retain_graph=True)\n",
    "        #ev_loss = keep_eigenvals_positive_loss(model.encoder.fuzzy_b[0])\n",
    "        #if ev_loss.item() > 0:\n",
    "        #    ev_loss.backward(retain_graph=True)\n",
    "        #(1 - fz.sum(-1)).mean().square().backward(retain_graph=True)\n",
    "        (1 - fz.sum(-1)).square().mean().backward(retain_graph=True)\n",
    "        loss_reconstruct.backward()\n",
    "        \n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), 1e-3)\n",
    "        optimizer.step()  \n",
    "        \n",
    "        if sched is not None:\n",
    "            sched.step()\n",
    "        \n",
    "    if writer is not None:\n",
    "        writer.add_scalar('FAD/LR', get_lr(optimizer), global_step=epoch)\n",
    "        \n",
    "    return prev_updates + len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed_random_z = torch.randn(16, fuzzy_rules_count).to(device)\n",
    "\n",
    "def test(model, dataloader, cur_step, epoch, writer=None):\n",
    "    model.eval() \n",
    "\n",
    "    test_recon_loss = 0\n",
    "    test_fz_loss = 0\n",
    "    test_fz_sum_loss = 0\n",
    "    \n",
    "    lab_true = []\n",
    "    lab_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, lab in tqdm(test_loader, desc='Test MNIST', disable=True):\n",
    "            data = data.view((-1,1,28,28)).to(device)\n",
    "            rates = get_arate(data)\n",
    "            \n",
    "            for f, l in  zip(rates, lab):\n",
    "                lab_pred.append(f)        \n",
    "                if l == mnist_class_anomaly:\n",
    "                    lab_true.append(1)\n",
    "                else:\n",
    "                    lab_true.append(0)\n",
    "                        \n",
    "    fpr, tpr, _ = metrics.roc_curve(lab_true, lab_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    embedings = []\n",
    "    labels_expected = []\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(dataloader, desc='Testing', disable=True):\n",
    "            data = data.to(device)\n",
    "\n",
    "            fz, mu = model.half_pass(data)  \n",
    "            x_reconstruct = model.decoder_pass(fz)\n",
    "            #x_centroidal = model.decoder(F.one_hot(fz.argmax(-1), fuzzy_rules_count).float())\n",
    "\n",
    "            embedings.append(mu.cpu().numpy())\n",
    "            labels_expected.append((target == mnist_class_anomaly).cpu().numpy())\n",
    "\n",
    "            loss_recon = compute_ae_loss(data, x_reconstruct)\n",
    "            fz_loss = fuzzy_term_volume_loss(model.encoder.fuzzy_a[0], fz)\n",
    "            \n",
    "            test_recon_loss += loss_recon.item()\n",
    "            test_fz_loss += fz_loss.item()\n",
    "            test_fz_sum_loss += fz.sum(-1).mean()\n",
    "            \n",
    "\n",
    "    embedings = np.concatenate(embedings, axis=0)\n",
    "    labels_expected = np.concatenate(labels_expected, axis=0)\n",
    "   \n",
    "    test_recon_loss /= len(dataloader)\n",
    "    test_fz_loss /= len(dataloader)\n",
    "    test_fz_sum_loss /= len(dataloader)\n",
    "    \n",
    "    print(f'[{cur_step}] Reconstruction loss: {test_recon_loss:.4f}, VOL: {test_fz_loss:.4f} SUM: {test_fz_sum_loss:.2f} AUC: {roc_auc:.4f}')\n",
    "    #print(f'Average activation stats: {model.decoder.fuzzy[2].get_norm_stats()}')\n",
    "    #print(f'Average centroid stats: {model.decoder.fuzzy[0].get_average_centroid()}')\n",
    "    if writer is not None:\n",
    "        writer.add_scalar('FAD/AUC', roc_auc, global_step=cur_step)\n",
    "        writer.add_scalar('FAD/Reconstruction', test_recon_loss, global_step=cur_step)\n",
    "        writer.add_scalar('FAD/Fz', test_fz_loss, global_step=cur_step)\n",
    "        writer.add_scalar('FAD/Sum', test_fz_sum_loss, global_step=cur_step)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2, figsize=(9, 4))\n",
    "        centroids_a = model.encoder.fuzzy_a[0].get_centroids().detach().cpu().numpy()\n",
    "        #centroids_b = model.encoder.fuzzy_b[0].get_centroids().detach().cpu().numpy()\n",
    "        ax[0].scatter(embedings[:, 0],      embedings[:,  1], c=labels_expected, cmap=binary_cmap, s=2)\n",
    "        ax[0].scatter(centroids_a[:, 0],      centroids_a[:, 1], marker='1', c='black', s= 50)\n",
    "        #ax[0].scatter(centroids_b[:, 0],      centroids_b[:, 1], marker='2', c='black', s= 50)\n",
    "        \n",
    "        ax[1].scatter(embedings[:, 0],      embedings[:,  2], c=labels_expected, cmap=binary_cmap, s=2)\n",
    "        ax[1].scatter(centroids_a[:, 1],      centroids_a[:, 2], marker='1', c='black', s= 50)\n",
    "        #ax[1].scatter(centroids_b[:, 1],      centroids_b[:, 2], marker='2', c='black', s= 50)\n",
    "    \n",
    "        act_fz = torch.diag(torch.ones(fuzzy_rules_count)).to(device)\n",
    "        samples = model.decoder(act_fz)\n",
    "        img_idx = 0\n",
    "        fign, axn = plt.subplots(8, 1 + fuzzy_rules_count//8, figsize=(1 + fuzzy_rules_count//8, 8), squeeze=False)\n",
    "        for i in range(8):\n",
    "            if img_idx >= fuzzy_rules_count:\n",
    "                continue\n",
    "            for j in range(fuzzy_rules_count//8):\n",
    "                axn[i, j].imshow(samples[img_idx].view(28, 28).cpu().detach().numpy(), cmap='gray')\n",
    "                axn[i, j].axis('off')\n",
    "                img_idx += 1\n",
    "\n",
    "        writer.add_figure('FAD/Emedding', fig, global_step=cur_step)\n",
    "        writer.add_figure('FAD/Samples', fign, global_step=cur_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_updates = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    prev_updates = train(model, train_loader, optimizer, sched, prev_updates, epoch, writer=writer)\n",
    "    test(model, test_loader, prev_updates, epoch, writer=writer)\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_eigenvals_positive_loss(model.encoder.fuzzy_a[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализируем результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_activation_stats(model, dataloader):\n",
    "    rulestat = {}\n",
    "    with torch.no_grad():\n",
    "        for _, (data, _) in enumerate(tqdm(dataloader)):\n",
    "            data = data.to(device)\n",
    "            fz, mu, rec_x = model.forward(data)\n",
    "            act_fz = fz.max(-1).indices.cpu().numpy()\n",
    "            for ind in act_fz:\n",
    "                rulestat[ind] = rulestat.get(ind, 0) + 1\n",
    "    return rulestat\n",
    "\n",
    "train_stat = get_activation_stats(model, train_loader)\n",
    "test_stat = get_activation_stats(model, test_loader)\n",
    "\n",
    "plt.bar(list(train_stat.keys()), train_stat.values(), 0.5, color='g')\n",
    "plt.bar(list(test_stat.keys()), test_stat.values(), 0.5, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_activation_stats_by_digit(digit, model, dataloader):\n",
    "    rulestat = {}\n",
    "    with torch.no_grad():\n",
    "        for _, (data, target) in enumerate(tqdm(dataloader)):\n",
    "        \n",
    "            data = data.to(device)\n",
    "            fz, mu, rec_x = model.forward(data)\n",
    "            act_fz = fz.max(-1).indices.cpu().numpy()\n",
    "            for ind, trg in zip(act_fz, target):\n",
    "                if trg == digit:\n",
    "                    rulestat[ind] = rulestat.get(ind, 0) + 1\n",
    "    return rulestat\n",
    "\n",
    "\n",
    "test_stat_by_digit = get_activation_stats_by_digit(8, model, test_loader)\n",
    "\n",
    "plt.bar(list(test_stat_by_digit.keys()), test_stat_by_digit.values(), 0.5, color='r')\n",
    "plt.xlim((-1, fuzzy_rules_count + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat_by_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    act_fz = torch.diag(torch.ones(fuzzy_rules_count)).to(device)\n",
    "    samples = model.decoder(act_fz)\n",
    "    img_idx = 0\n",
    "    fig, ax = plt.subplots(8, fuzzy_rules_count//8, figsize=(fuzzy_rules_count//8, 8))\n",
    "    for i in range(8):\n",
    "        for j in range(fuzzy_rules_count//8):\n",
    "            ax[i, j].imshow(samples[img_idx].view(28, 28).cpu().detach().numpy(), cmap='gray')\n",
    "            ax[i, j].axis('off')\n",
    "            img_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(64, fuzzy_rules_count).to(device)\n",
    "    samples = model.decoder_pass(z)\n",
    "\n",
    "    # Plot the generated images\n",
    "    fig, ax = plt.subplots(8, 8, figsize=(8, 8))\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            ax[i, j].imshow(samples[i*8+j].view(28, 28).cpu().detach().numpy(), cmap='gray')\n",
    "            ax[i, j].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_arate(inp):\n",
    "    fz, mu, x_recon = model.forward(inp)\n",
    "    return (1 - ssim(x_recon, inp)).cpu().numpy()#fz.sum(-1).cpu().numpy() #xent_continuous_ber((x_recon + 1)/2, (inp + 1)/2).cpu().numpy()# #ssim((inp + 1)/2, (recon_x+1)/2).cpu().numpy() #fz.sum(-1).cpu().numpy()#(inp - x_recon).abs().sum(-1).sum(-1).mean(-1).cpu().numpy()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firings_mnist = {}\n",
    "firings_mnist['MNIST'] = []\n",
    "firings_mnist['DISSIDENT'] = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in tqdm(test_loader, desc='MNIST HIST'):\n",
    "        data = data.view((-1,1,28,28)).to(device)\n",
    "        rates = get_arate(data)\n",
    "        for f, l in  zip(rates, target):\n",
    "            if l != mnist_class_anomaly:\n",
    "                firings_mnist['MNIST'].append(f)\n",
    "            else:\n",
    "                firings_mnist['DISSIDENT'].append(f)\n",
    "        \n",
    "\n",
    "labels, data = firings_mnist.keys(), firings_mnist.values()\n",
    "\n",
    "fig = plt.figure(figsize =(12, 2))\n",
    "plt.boxplot(data, notch=True, showfliers=False)\n",
    "plt.xticks(range(1, len(labels) + 1), labels)\n",
    "plt.show()\n",
    "\n",
    "writer.add_figure('Anomaly Detection', fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    firing_levels = []\n",
    "    lab_true = []\n",
    "    lab_pred = []\n",
    "\n",
    "    for data, lab in tqdm(test_loader, desc='Test MNIST', disable=True):\n",
    "        data = data.view((-1,1,28,28)).to(device)\n",
    "        rates = get_arate(data)\n",
    "        \n",
    "        for f, l in  zip(rates, lab):\n",
    "            firing_levels.append(f)\n",
    "            lab_pred.append(f)        \n",
    "            if l == mnist_class_anomaly:\n",
    "                lab_true.append(1)\n",
    "            else:\n",
    "                lab_true.append(0)\n",
    "                    \n",
    "    fpr, tpr, threshold = metrics.roc_curve(lab_true, lab_pred)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "    fig = plt.figure(figsize =(4, 4))\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    writer.add_figure('ROC', fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def show_plot():\n",
    "    #centroids = model.encoder.fuzzy[0].get_centroids().detach().cpu().numpy()\n",
    "    embedings = []\n",
    "    labels_expected = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc='Encoding'):\n",
    "            data = data.view((-1,1,28,28)).to(device)\n",
    "            fz, mu, rec_x = model.forward(data)\n",
    "            embedings.append(mu.cpu().numpy())\n",
    "            labels_expected.append((target == mnist_class_anomaly).cpu().numpy())\n",
    "    embedings = np.concatenate(embedings, axis=0)\n",
    "    labels_expected = np.concatenate(labels_expected, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    R, C = 1, 3\n",
    "\n",
    "    plt.subplot(R, C, 1)\n",
    "    plt.title(\"MNIST XY\")\n",
    "    \n",
    "    plt.scatter(embedings[:, 0],      embedings[:,  1], c=labels_expected, cmap=binary_cmap, s=2)\n",
    "    #plt.scatter(centroids[:, 0],      centroids[:, 1], marker='1', c='black', s= 50)\n",
    "\n",
    "    plt.subplot(R, C, 2)\n",
    "    plt.title(\"MNIST XZ\")\n",
    "    plt.scatter(embedings[:, 0],      embedings[:,  2], c=labels_expected, cmap=binary_cmap, s=2)\n",
    "    #plt.scatter(centroids[:, 0],      centroids[:, 2], marker='1', c='black', s= 50)\n",
    "\n",
    "    \n",
    "show_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_item_reconstructio(ind):\n",
    "    for data, trg in iter(test_loader):\n",
    "        data = data.to(device)\n",
    "        fz, mu, rec_x = model.forward(data)\n",
    "        \n",
    "        plt.figure(figsize=(24, 6))\n",
    "\n",
    "        R, C = 1, 6\n",
    "\n",
    "        plt.subplot(R, C, 1)\n",
    "        plt.imshow(data[ind].cpu().squeeze())\n",
    "        plt.subplot(R, C, 2)\n",
    "        plt.imshow(rec_x[ind].detach().cpu().squeeze())\n",
    "        \n",
    "        plt.subplot(R, C, 3)\n",
    "        plt.imshow((rec_x[ind] - data[ind]).abs().detach().cpu().squeeze())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_item_reconstructio(4)\n",
    "show_item_reconstructio(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = optimal_threshold\n",
    "n = 0\n",
    "fig, ax = plt.subplots(10, 10, figsize=(10, 10))\n",
    "with torch.no_grad():\n",
    "    for data, labels in tqdm(test_loader, desc='EMNIST VIS'):\n",
    "        if n >= 100:\n",
    "            break\n",
    "        data = data.view((-1, 1, 28, 28)).to(device) \n",
    "        \n",
    "        arate = get_arate(data)\n",
    "        \n",
    "        for i in range(data.shape[0]):\n",
    "            if(arate[i] > threshold):\n",
    "                img = data[i]\n",
    "                ax[int(n / 10), int(n % 10)].imshow(img.view(28, 28).cpu().detach().numpy(), cmap='gray')\n",
    "                ax[int(n / 10), int(n % 10)].axis('off')\n",
    "                n = n + 1\n",
    "                    \n",
    "                if n >= 100:\n",
    "                    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
